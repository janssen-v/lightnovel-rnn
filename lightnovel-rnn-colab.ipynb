{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_zfeOsF-0zx"
      },
      "source": [
        "### Import Libraries\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SfAtmhSa9M91"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhyW2FeHYw8m"
      },
      "source": [
        "### Check GPU functionality"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.config.list_physical_devices('GPU')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf.test.is_built_with_cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSG4PEtLY4nJ",
        "outputId": "78fcb770-9a94-48bf-beb3-71825bacd925"
      },
      "outputs": [],
      "source": [
        "tf.test.gpu_device_name()\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQ0rqO5yOM0u"
      },
      "source": [
        "### Download Light Novel Title dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CpPz1KLOOWOs",
        "outputId": "1410aef5-f244-4da2-8e0b-e7b4ca2873e3"
      },
      "outputs": [],
      "source": [
        "filepath = tf.keras.utils.get_file('light_novel_titles_clean_v2.txt', 'https://drive.google.com/uc?export=download&id=13ExvJcOr0l8LZD1gHCiYJn2C_pKx8v1D')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCfdO4Z-PI4R"
      },
      "source": [
        "### Check data content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQqEBgkMPU6T",
        "outputId": "8a61c56d-dddc-4dfe-c0cc-3f0b24af4471"
      },
      "outputs": [],
      "source": [
        "text = open(filepath, 'rb').read().decode(encoding='utf-16')\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzz485BQByf",
        "outputId": "60ec7942-77f9-42af-c946-98e0f06ba4c3"
      },
      "outputs": [],
      "source": [
        "# Check first 250 characters\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8mC4pUsVQH6c",
        "outputId": "43a320bd-d5e7-4ed8-843f-f49707571fae"
      },
      "outputs": [],
      "source": [
        "# Check amount of unique characters\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIKgtLtvQS2X"
      },
      "source": [
        "## Text Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Fs2ym7zQWp5"
      },
      "source": [
        "### Text Vectorization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rZPafTGNQa5r"
      },
      "outputs": [],
      "source": [
        "chars_to_ids = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)\n",
        "ids_to_chars = tf.keras.layers.StringLookup(vocabulary=chars_to_ids.get_vocabulary(), invert=True, mask_token=None)\n",
        "\n",
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(ids_to_chars(ids), axis =-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqRYOGX-RxXA"
      },
      "source": [
        "### Training Examples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RH47CRBFRzkl",
        "outputId": "5d2e6748-dac5-44d1-df41-fa17cecb88aa"
      },
      "outputs": [],
      "source": [
        "all_ids = chars_to_ids(tf.strings.unicode_split(text,'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XS3kzwSoSN6N"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iKRUKaw0SSj1",
        "outputId": "aa915f88-417f-4b8f-93be-aef2c5c97020"
      },
      "outputs": [],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(ids_to_chars(ids).numpy().decode('UTF-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gV4jHePrSfVM"
      },
      "outputs": [],
      "source": [
        "seq_length = 100\n",
        "examples_per_epoch = len(text)//(seq_length)+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjhJHoI1S9nB",
        "outputId": "428be123-1396-4375-d50d-09340340b656"
      },
      "outputs": [],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "for seq in sequences.take(1):\n",
        "  print(ids_to_chars(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pkmdSG02TCKj",
        "outputId": "13bae08e-9b39-4ca1-dce4-bc75eb617bfe"
      },
      "outputs": [],
      "source": [
        "for seq in sequences.take(5):\n",
        "  print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5IKGxNUTIHz"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-72859KTSd4"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c808j6SUTg82",
        "outputId": "80d5e3e2-88de-466c-d54c-9ce8d14f0060"
      },
      "outputs": [],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input:\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INvxDniVTvA9"
      },
      "source": [
        "### Training batch creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qczZGEqhTyoe",
        "outputId": "d45dc51e-086a-4c95-e350-5566d99cdf81"
      },
      "outputs": [],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "# Buffer size for dataset shuffle\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1FKUbFOUMkp"
      },
      "source": [
        "## Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEOirm8pUOiN"
      },
      "outputs": [],
      "source": [
        "# Length of vocabulary in chars\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7YJXnDxUbEb"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "                                    \n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32zRGBSzVWA6"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    # Be sure vocabulary size matches the 'StringLookup' layers.\n",
        "    vocab_size=len(chars_to_ids.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3LFJfz2VysI"
      },
      "source": [
        "## Model test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kmvtJ-ugV2V6",
        "outputId": "36d2c19b-4b61-4057-93f7-ecb13fcd1190"
      },
      "outputs": [],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "  example_batch_predictions = model(input_example_batch)\n",
        "  print(example_batch_predictions.shape, \"(batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MY3GG7UZWF_2",
        "outputId": "9ac251ca-9f23-4f7f-b60f-aff0f2d2a9ff"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjyEr57EWKg7"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples = 1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF0n23hwWa3D",
        "outputId": "95e88d88-eea8-4b8f-8621-ef7e67eb972a"
      },
      "outputs": [],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrrzRkSFWdFf",
        "outputId": "2e06cc52-acd1-4976-b446-cca339e298fb"
      },
      "outputs": [],
      "source": [
        "# Decode untrained model prediction\n",
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XN8SHc7dWv9x"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_i5Cdk5WySF"
      },
      "source": [
        "### Optimizer and Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "py82VpQIW0Kz"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7-7zXkXW6C1",
        "outputId": "37e7ae02-5337-408e-dc46-50ec61e36fb0"
      },
      "outputs": [],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \"(batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLtp5lxpXTQy",
        "outputId": "a615a057-35b3-4138-8917-d0f92660cacb"
      },
      "outputs": [],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGscm8OrXXDN"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42f05c8fXbQk"
      },
      "source": [
        "### Configure checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQUf0HRCXdOD"
      },
      "outputs": [],
      "source": [
        "# Checkpoint save directory\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "# Name of checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61dTVqYuXsZ_"
      },
      "source": [
        "### Start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-a4RTFQXvTh"
      },
      "outputs": [],
      "source": [
        "EPOCHS=100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JsaNkmGXxGL",
        "outputId": "bac21fd6-6ae7-4e60-bc28-47d83ef79e7d"
      },
      "outputs": [],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5FyP9B1g--e"
      },
      "outputs": [],
      "source": [
        "TEMP = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kUHrUZu0YQ9Q"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, ids_to_chars, chars_to_ids, temperature=TEMP):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.ids_to_chars = ids_to_chars\n",
        "    self.chars_to_ids = chars_to_ids\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.chars_to_ids(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(chars_to_ids.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.chars_to_ids(input_chars).to_tensor()\n",
        "\n",
        "    # Run model\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply prediction mask: prevent UNK generation.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert token ids to characters\n",
        "    predicted_chars = self.ids_to_chars(predicted_ids)\n",
        "\n",
        "    # Return characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nFf6wOvlYS14"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, ids_to_chars, chars_to_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZtuDzci2qp_r"
      },
      "outputs": [],
      "source": [
        "SEED = \"Is this a light novel title?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBWRSXRcYZX0",
        "outputId": "2c0b94fe-668a-4b02-9012-d51f373fe496"
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "# Start String\n",
        "next_char = tf.constant([SEED])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  # TODO: Check if generated title is in source text, if yes -> regenerate\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "result = result[0].numpy().decode('utf-8')\n",
        "end = time.time()\n",
        "print(result)\n",
        "print('\\nRun time:', end - start)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "61dTVqYuXsZ_"
      ],
      "name": "Light Novel Title Recurrent Neural Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
